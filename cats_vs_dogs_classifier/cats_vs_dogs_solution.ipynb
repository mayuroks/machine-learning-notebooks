{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "import os\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=[]\n",
    "labels=[]\n",
    "\n",
    "cats=os.listdir(\"small_train\")\n",
    "for cat in cats:\n",
    "    imag=cv2.imread(\"small_train/\"+cat)\n",
    "    img_from_ar = Image.fromarray(imag, 'RGB')\n",
    "    resized_image = img_from_ar.resize((50, 50))\n",
    "    \n",
    "    data.append(np.array(resized_image))\n",
    "    labels.append(0)\n",
    "    \n",
    "dogs=os.listdir(\"preview\")\n",
    "for dog in dogs:\n",
    "    imag=cv2.imread(\"preview/\"+dog)\n",
    "    img_from_ar = Image.fromarray(imag, 'RGB')\n",
    "    resized_image = img_from_ar.resize((50, 50))\n",
    "    \n",
    "    data.append(np.array(resized_image))\n",
    "    labels.append(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "animals = np.array(data)\n",
    "labels = np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"animals\",animals)\n",
    "np.save(\"labels\",labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "s=np.arange(animals.shape[0])\n",
    "np.random.shuffle(s)\n",
    "animals=animals[s]\n",
    "labels=labels[s]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes=len(np.unique(labels))\n",
    "data_length=len(animals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train,x_test)=animals[(int)(0.1*data_length):],animals[:(int)(0.1*data_length)]\n",
    "x_train = x_train.astype('float32')/255\n",
    "x_test = x_test.astype('float32')/255\n",
    "train_length=len(x_train)\n",
    "test_length=len(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "(y_train,y_test)=labels[(int)(0.1*data_length):],labels[:(int)(0.1*data_length)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.utils import np_utils\n",
    "#One hot encoding\n",
    "y_train=keras.utils.to_categorical(y_train,num_classes)\n",
    "y_test=keras.utils.to_categorical(y_test,num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D,MaxPooling2D,Dense,Flatten,Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_7 (Conv2D)            (None, 50, 50, 16)        208       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2 (None, 25, 25, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 25, 25, 32)        2080      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2 (None, 12, 12, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 12, 12, 64)        8256      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_9 (MaxPooling2 (None, 6, 6, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 6, 6, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 2304)              0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 500)               1152500   \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 500)               0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 2)                 1002      \n",
      "=================================================================\n",
      "Total params: 1,164,046\n",
      "Trainable params: 1,164,046\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model=Sequential()\n",
    "model.add(Conv2D(filters=16,kernel_size=2,padding=\"same\",activation=\"relu\",input_shape=(50,50,3)))\n",
    "\n",
    "model.add(MaxPooling2D(pool_size=2))\n",
    "\n",
    "model.add(Conv2D(filters=32,kernel_size=2,padding=\"same\",activation=\"relu\"))\n",
    "\n",
    "model.add(MaxPooling2D(pool_size=2))\n",
    "\n",
    "model.add(Conv2D(filters=64,kernel_size=2,padding=\"same\",activation=\"relu\"))\n",
    "\n",
    "model.add(MaxPooling2D(pool_size=2))\n",
    "\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(500,activation=\"relu\"))\n",
    "\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Dense(2,activation=\"softmax\"))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer='adam', \n",
    "                  metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "72/72 [==============================] - 16s 220ms/step - loss: 0.7262 - acc: 0.5000\n",
      "Epoch 2/100\n",
      "72/72 [==============================] - 4s 49ms/step - loss: 0.6781 - acc: 0.7222\n",
      "Epoch 3/100\n",
      "72/72 [==============================] - 3s 48ms/step - loss: 0.6203 - acc: 0.7639\n",
      "Epoch 4/100\n",
      "72/72 [==============================] - 3s 48ms/step - loss: 0.6113 - acc: 0.7778\n",
      "Epoch 5/100\n",
      "72/72 [==============================] - 3s 48ms/step - loss: 0.5423 - acc: 0.7222\n",
      "Epoch 6/100\n",
      "72/72 [==============================] - 4s 49ms/step - loss: 0.5432 - acc: 0.7222\n",
      "Epoch 7/100\n",
      "72/72 [==============================] - 4s 49ms/step - loss: 0.4692 - acc: 0.7222\n",
      "Epoch 8/100\n",
      "72/72 [==============================] - 4s 50ms/step - loss: 0.3873 - acc: 0.7361\n",
      "Epoch 9/100\n",
      "72/72 [==============================] - 3s 48ms/step - loss: 0.3233 - acc: 0.8056\n",
      "Epoch 10/100\n",
      "72/72 [==============================] - 3s 47ms/step - loss: 0.2579 - acc: 0.9583\n",
      "Epoch 11/100\n",
      "72/72 [==============================] - 3s 48ms/step - loss: 0.1981 - acc: 0.9861\n",
      "Epoch 12/100\n",
      "72/72 [==============================] - 3s 47ms/step - loss: 0.1632 - acc: 0.9861\n",
      "Epoch 13/100\n",
      "72/72 [==============================] - 3s 45ms/step - loss: 0.1287 - acc: 0.9583\n",
      "Epoch 14/100\n",
      "72/72 [==============================] - 3s 48ms/step - loss: 0.0762 - acc: 0.9722\n",
      "Epoch 15/100\n",
      "72/72 [==============================] - 3s 46ms/step - loss: 0.0759 - acc: 0.9861\n",
      "Epoch 16/100\n",
      "72/72 [==============================] - 3s 47ms/step - loss: 0.0439 - acc: 0.9861\n",
      "Epoch 17/100\n",
      "72/72 [==============================] - 4s 49ms/step - loss: 0.0321 - acc: 1.0000\n",
      "Epoch 18/100\n",
      "72/72 [==============================] - 3s 47ms/step - loss: 0.0192 - acc: 1.0000\n",
      "Epoch 19/100\n",
      "72/72 [==============================] - 3s 47ms/step - loss: 0.0178 - acc: 1.0000\n",
      "Epoch 20/100\n",
      "72/72 [==============================] - 4s 49ms/step - loss: 0.0104 - acc: 1.0000\n",
      "Epoch 21/100\n",
      "72/72 [==============================] - 3s 46ms/step - loss: 0.0111 - acc: 1.0000\n",
      "Epoch 22/100\n",
      "72/72 [==============================] - 3s 48ms/step - loss: 0.0100 - acc: 1.0000\n",
      "Epoch 23/100\n",
      "72/72 [==============================] - 3s 45ms/step - loss: 0.0109 - acc: 1.0000\n",
      "Epoch 24/100\n",
      "72/72 [==============================] - 4s 50ms/step - loss: 0.0080 - acc: 1.0000\n",
      "Epoch 25/100\n",
      "72/72 [==============================] - 3s 48ms/step - loss: 0.0040 - acc: 1.0000\n",
      "Epoch 26/100\n",
      "72/72 [==============================] - 3s 46ms/step - loss: 0.0047 - acc: 1.0000\n",
      "Epoch 27/100\n",
      "72/72 [==============================] - 3s 45ms/step - loss: 0.0044 - acc: 1.0000\n",
      "Epoch 28/100\n",
      "72/72 [==============================] - 4s 50ms/step - loss: 0.0033 - acc: 1.0000\n",
      "Epoch 29/100\n",
      "72/72 [==============================] - 3s 48ms/step - loss: 0.0010 - acc: 1.0000\n",
      "Epoch 30/100\n",
      "72/72 [==============================] - 3s 48ms/step - loss: 0.0014 - acc: 1.0000\n",
      "Epoch 31/100\n",
      "72/72 [==============================] - 3s 47ms/step - loss: 0.0012 - acc: 1.0000\n",
      "Epoch 32/100\n",
      "72/72 [==============================] - 3s 47ms/step - loss: 0.0021 - acc: 1.0000\n",
      "Epoch 33/100\n",
      "72/72 [==============================] - 3s 47ms/step - loss: 0.0010 - acc: 1.0000\n",
      "Epoch 34/100\n",
      "72/72 [==============================] - 4s 50ms/step - loss: 0.0016 - acc: 1.0000\n",
      "Epoch 35/100\n",
      "72/72 [==============================] - 4s 50ms/step - loss: 9.2012e-04 - acc: 1.0000\n",
      "Epoch 36/100\n",
      "72/72 [==============================] - 4s 50ms/step - loss: 7.6299e-04 - acc: 1.0000\n",
      "Epoch 37/100\n",
      "72/72 [==============================] - 3s 48ms/step - loss: 7.5175e-04 - acc: 1.0000\n",
      "Epoch 38/100\n",
      "72/72 [==============================] - 3s 48ms/step - loss: 7.0651e-04 - acc: 1.0000\n",
      "Epoch 39/100\n",
      "72/72 [==============================] - 4s 49ms/step - loss: 3.4355e-04 - acc: 1.0000\n",
      "Epoch 40/100\n",
      "72/72 [==============================] - 4s 49ms/step - loss: 6.2244e-04 - acc: 1.0000\n",
      "Epoch 41/100\n",
      "72/72 [==============================] - 3s 48ms/step - loss: 8.7100e-04 - acc: 1.0000\n",
      "Epoch 42/100\n",
      "72/72 [==============================] - 3s 47ms/step - loss: 3.5519e-04 - acc: 1.0000\n",
      "Epoch 43/100\n",
      "72/72 [==============================] - 3s 48ms/step - loss: 9.9976e-04 - acc: 1.0000\n",
      "Epoch 44/100\n",
      "72/72 [==============================] - 3s 48ms/step - loss: 3.7271e-04 - acc: 1.0000\n",
      "Epoch 45/100\n",
      "72/72 [==============================] - 4s 49ms/step - loss: 3.2329e-04 - acc: 1.0000\n",
      "Epoch 46/100\n",
      "72/72 [==============================] - 3s 47ms/step - loss: 2.7242e-04 - acc: 1.0000\n",
      "Epoch 47/100\n",
      "72/72 [==============================] - 3s 47ms/step - loss: 3.3953e-04 - acc: 1.0000\n",
      "Epoch 48/100\n",
      "72/72 [==============================] - 4s 51ms/step - loss: 4.2888e-04 - acc: 1.0000\n",
      "Epoch 49/100\n",
      "72/72 [==============================] - 4s 52ms/step - loss: 2.7459e-04 - acc: 1.0000\n",
      "Epoch 50/100\n",
      "72/72 [==============================] - 4s 52ms/step - loss: 3.6531e-04 - acc: 1.0000\n",
      "Epoch 51/100\n",
      "72/72 [==============================] - 4s 51ms/step - loss: 2.6557e-04 - acc: 1.0000\n",
      "Epoch 52/100\n",
      "72/72 [==============================] - 4s 53ms/step - loss: 1.4021e-04 - acc: 1.0000\n",
      "Epoch 53/100\n",
      "72/72 [==============================] - 3s 47ms/step - loss: 2.9642e-04 - acc: 1.0000\n",
      "Epoch 54/100\n",
      "72/72 [==============================] - 4s 49ms/step - loss: 3.3424e-04 - acc: 1.0000\n",
      "Epoch 55/100\n",
      "72/72 [==============================] - 4s 50ms/step - loss: 2.0126e-04 - acc: 1.0000\n",
      "Epoch 56/100\n",
      "72/72 [==============================] - 4s 49ms/step - loss: 4.4310e-04 - acc: 1.0000\n",
      "Epoch 57/100\n",
      "72/72 [==============================] - 3s 47ms/step - loss: 2.3956e-04 - acc: 1.0000\n",
      "Epoch 58/100\n",
      "72/72 [==============================] - 3s 47ms/step - loss: 2.0748e-04 - acc: 1.0000\n",
      "Epoch 59/100\n",
      "72/72 [==============================] - 3s 45ms/step - loss: 2.3112e-04 - acc: 1.0000\n",
      "Epoch 60/100\n",
      "72/72 [==============================] - 3s 46ms/step - loss: 1.9908e-04 - acc: 1.0000\n",
      "Epoch 61/100\n",
      "72/72 [==============================] - 3s 48ms/step - loss: 4.5059e-04 - acc: 1.0000\n",
      "Epoch 62/100\n",
      "72/72 [==============================] - 4s 53ms/step - loss: 3.0653e-04 - acc: 1.0000\n",
      "Epoch 63/100\n",
      "72/72 [==============================] - 4s 50ms/step - loss: 1.6951e-04 - acc: 1.0000\n",
      "Epoch 64/100\n",
      "72/72 [==============================] - 3s 47ms/step - loss: 1.7294e-04 - acc: 1.0000\n",
      "Epoch 65/100\n",
      "72/72 [==============================] - 3s 48ms/step - loss: 6.8333e-05 - acc: 1.0000\n",
      "Epoch 66/100\n",
      "72/72 [==============================] - 3s 47ms/step - loss: 1.3687e-04 - acc: 1.0000\n",
      "Epoch 67/100\n",
      "72/72 [==============================] - 4s 49ms/step - loss: 2.0682e-04 - acc: 1.0000\n",
      "Epoch 68/100\n",
      "72/72 [==============================] - 4s 49ms/step - loss: 7.0486e-05 - acc: 1.0000\n",
      "Epoch 69/100\n",
      "72/72 [==============================] - 4s 50ms/step - loss: 1.0533e-04 - acc: 1.0000\n",
      "Epoch 70/100\n",
      "72/72 [==============================] - 3s 48ms/step - loss: 7.5451e-05 - acc: 1.0000\n",
      "Epoch 71/100\n",
      "72/72 [==============================] - 4s 51ms/step - loss: 1.5299e-04 - acc: 1.0000\n",
      "Epoch 72/100\n",
      "72/72 [==============================] - 4s 52ms/step - loss: 1.2966e-04 - acc: 1.0000\n",
      "Epoch 73/100\n",
      "72/72 [==============================] - 3s 47ms/step - loss: 8.2483e-05 - acc: 1.0000\n",
      "Epoch 74/100\n",
      "72/72 [==============================] - 4s 50ms/step - loss: 1.9552e-04 - acc: 1.0000\n",
      "Epoch 75/100\n",
      "72/72 [==============================] - 3s 47ms/step - loss: 2.0968e-04 - acc: 1.0000\n",
      "Epoch 76/100\n",
      "72/72 [==============================] - 4s 50ms/step - loss: 6.2964e-05 - acc: 1.0000\n",
      "Epoch 77/100\n",
      "72/72 [==============================] - 3s 47ms/step - loss: 5.4626e-05 - acc: 1.0000\n",
      "Epoch 78/100\n",
      "72/72 [==============================] - 4s 50ms/step - loss: 1.1873e-04 - acc: 1.0000\n",
      "Epoch 79/100\n",
      "72/72 [==============================] - 4s 50ms/step - loss: 1.2926e-04 - acc: 1.0000\n",
      "Epoch 80/100\n",
      "72/72 [==============================] - 4s 49ms/step - loss: 5.5375e-05 - acc: 1.0000\n",
      "Epoch 81/100\n",
      "72/72 [==============================] - 3s 47ms/step - loss: 6.0298e-05 - acc: 1.0000\n",
      "Epoch 82/100\n",
      "72/72 [==============================] - 3s 46ms/step - loss: 3.9823e-05 - acc: 1.0000\n",
      "Epoch 83/100\n",
      "72/72 [==============================] - 4s 51ms/step - loss: 4.4468e-05 - acc: 1.0000\n",
      "Epoch 84/100\n",
      "72/72 [==============================] - 4s 52ms/step - loss: 7.5244e-05 - acc: 1.0000\n",
      "Epoch 85/100\n",
      "72/72 [==============================] - 3s 47ms/step - loss: 3.8279e-05 - acc: 1.0000\n",
      "Epoch 86/100\n",
      "72/72 [==============================] - 4s 49ms/step - loss: 3.9533e-05 - acc: 1.0000\n",
      "Epoch 87/100\n",
      "72/72 [==============================] - 4s 50ms/step - loss: 8.9724e-05 - acc: 1.0000\n",
      "Epoch 88/100\n",
      "72/72 [==============================] - 3s 48ms/step - loss: 4.5903e-05 - acc: 1.0000\n",
      "Epoch 89/100\n",
      "72/72 [==============================] - 4s 49ms/step - loss: 9.6515e-05 - acc: 1.0000\n",
      "Epoch 90/100\n",
      "72/72 [==============================] - 3s 47ms/step - loss: 7.8087e-05 - acc: 1.0000\n",
      "Epoch 91/100\n",
      "72/72 [==============================] - 4s 50ms/step - loss: 2.9882e-05 - acc: 1.0000\n",
      "Epoch 92/100\n",
      "72/72 [==============================] - 4s 51ms/step - loss: 5.9119e-05 - acc: 1.0000\n",
      "Epoch 93/100\n",
      "72/72 [==============================] - 4s 51ms/step - loss: 3.9862e-05 - acc: 1.0000\n",
      "Epoch 94/100\n",
      "72/72 [==============================] - 4s 50ms/step - loss: 4.8305e-05 - acc: 1.0000\n",
      "Epoch 95/100\n",
      "72/72 [==============================] - 4s 50ms/step - loss: 4.8123e-05 - acc: 1.0000\n",
      "Epoch 96/100\n",
      "72/72 [==============================] - 3s 48ms/step - loss: 5.2347e-05 - acc: 1.0000\n",
      "Epoch 97/100\n",
      "72/72 [==============================] - 3s 46ms/step - loss: 3.6666e-05 - acc: 1.0000\n",
      "Epoch 98/100\n",
      "72/72 [==============================] - 3s 45ms/step - loss: 6.0507e-05 - acc: 1.0000\n",
      "Epoch 99/100\n",
      "72/72 [==============================] - 3s 48ms/step - loss: 2.7604e-05 - acc: 1.0000\n",
      "Epoch 100/100\n",
      "72/72 [==============================] - 3s 46ms/step - loss: 6.9211e-05 - acc: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x137a74a1470>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train,y_train,batch_size=50\n",
    "          ,epochs=100,verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "7/7 [==============================] - 0s 10ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.5613833665847778, 0.8571428656578064]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_test, y_test, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_array(img):\n",
    "    im = cv2.imread(img)\n",
    "    img = Image.fromarray(im, 'RGB')\n",
    "    image = img.resize((50, 50))\n",
    "    return np.array(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_animal_name(label):\n",
    "    if label==0:\n",
    "        return \"cat\"\n",
    "    if label==1:\n",
    "        return \"dog\"\n",
    "    if label==2:\n",
    "        return \"bird\"\n",
    "    if label==3:\n",
    "        return \"fish\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_animal(file):\n",
    "    print(\"Predicting .................................\")\n",
    "    ar=convert_to_array(file)\n",
    "    ar=ar/255\n",
    "    label=1\n",
    "    a=[]\n",
    "    a.append(ar)\n",
    "    a=np.array(a)\n",
    "    score=model.predict(a,verbose=1)\n",
    "    print(score)\n",
    "    label_index=np.argmax(score)\n",
    "    print(label_index)\n",
    "    acc=np.max(score)\n",
    "    animal=get_animal_name(label_index)\n",
    "    print(animal)\n",
    "    print(\"The predicted Animal is a \"+animal+\" with accuracy =    \"+str(acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting .................................\n",
      "1/1 [==============================] - 0s 0us/step\n",
      "[[0.88458717 0.11541288]]\n",
      "0\n",
      "cat\n",
      "The predicted Animal is a cat with accuracy =    0.88458717\n"
     ]
    }
   ],
   "source": [
    "predict_animal(\"ranveersingh4.jpg\")\n",
    "# predict_animal(\"IMG_2243.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
